{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras import regularizers\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.6\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset we use here is 'mnist.pkl.gz' which is divided into training, validation and test data. The following function <i> load_data() </i> unpacks the file and extracts the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    f.seek(0)\n",
    "    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature dataset is:[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "The target dataset is:[5 0 4 ... 8 4 8]\n",
      "The number of examples in the training dataset is:50000\n",
      "The number of points in a single input is:784\n"
     ]
    }
   ],
   "source": [
    "print(\"The feature dataset is:\" + str(training_data[0]))\n",
    "print(\"The target dataset is:\" + str(training_data[1]))\n",
    "print(\"The number of examples in the training dataset is:\" + str(len(training_data[0])))\n",
    "print(\"The number of points in a single input is:\" + str(len(training_data[0][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as discussed earlier in the lectures, the target variable is converted to a one hot matrix. We use the function <i> one_hot </i> to convert the target dataset to one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(j):\n",
    "    # input is the target dataset of shape (1, m) where m is the number of data points\n",
    "    # returns a 2 dimensional array of shape (10, m) where each target value is converted to a one hot encoding\n",
    "    # Look at the next block of code for a better understanding of one hot encoding\n",
    "    n = j.shape[0]\n",
    "    new_array = np.zeros((10, n))\n",
    "    index = 0\n",
    "    for res in j:\n",
    "        new_array[res][index] = 1.0\n",
    "        index = index + 1\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "one_hot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_wrapper():\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    \n",
    "    training_inputs = np.array(tr_d[0][:]).T\n",
    "    training_results = np.array(tr_d[1][:])\n",
    "    train_set_y = one_hot(training_results)\n",
    "    \n",
    "    validation_inputs = np.array(va_d[0][:]).T\n",
    "    validation_results = np.array(va_d[1][:])\n",
    "    validation_set_y = one_hot(validation_results)\n",
    "    \n",
    "    test_inputs = np.array(te_d[0][:]).T\n",
    "    test_results = np.array(te_d[1][:])\n",
    "    test_set_y = one_hot(test_results)\n",
    "    \n",
    "    return (training_inputs, train_set_y, validation_inputs, validation_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x, train_set_y, test_set_x, test_set_y = data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementing in Keras, the input training and input target dataset are supposed to have shape (m, n) where m is the number of training samples and n is the number of parts in a single input.\n",
    "<br> Hence, let create the desired dataset shapes by taking transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set_x.T\n",
    "train_set_y = train_set_y.T\n",
    "test_set_x = test_set_x.T\n",
    "test_set_y = test_set_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if the datasets are in the desired shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (50000, 784)\n",
      "train_set_y shape: (50000, 10)\n",
      "test_set_x shape: (10000, 784)\n",
      "test_set_y shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (\"train_set_x shape: \" + str(train_set_x.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us visualise the dataset. Feel free to change the index to see if the training data has been correctly tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc0e809a2b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDfUVWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc0f16a1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index  = 1000\n",
    "k = train_set_x[index,:]\n",
    "k = k.reshape((28, 28))\n",
    "plt.title('Label is {label}'.format(label= training_data[1][index]))\n",
    "plt.imshow(k, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a framework. So, to implement a neural network model in Keras, we first create an instance of Sequential(). <br>\n",
    "The Sequential model is a linear stack of layers. We then keep adding Dense layers that are fully connected layers as we desire.<br><br>\n",
    "We have included Dropout using <i> nn_model.add(Dropout(0.3)) </i> <br><br>\n",
    "We can also include regularization using the command <br> <i> nn_model.add(Dense(21, activation='relu', kernel_regularizer=regularizers.l2(0.01))) </i> <br>instead of <br> <i> nn_model.add(Dense(21, activation='relu')) </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(35, input_dim=784, activation='relu'))\n",
    "nn_model.add(Dropout(0.3))\n",
    "nn_model.add(Dense(21, activation = 'relu'))\n",
    "nn_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the model on the training datasets, we compile the model in which we define various things like the loss function, the optimizer and the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to fit the model on the training input and training target dataset, we run the following command using a minibatch of size 10 and 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 0.5131 - acc: 0.8409\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s 302us/step - loss: 0.3239 - acc: 0.9016\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 0.2862 - acc: 0.9105\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 0.2690 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 0.2542 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s 294us/step - loss: 0.2452 - acc: 0.9224\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s 299us/step - loss: 0.2339 - acc: 0.9260\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s 298us/step - loss: 0.2284 - acc: 0.9282\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 0.2208 - acc: 0.9301\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 0.2133 - acc: 0.9337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc0e46ee828>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(train_set_x, train_set_y, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 57us/step\n",
      "\n",
      "acc: 96.92%\n"
     ]
    }
   ],
   "source": [
    "scores_train = nn_model.evaluate(train_set_x, train_set_y)\n",
    "print(\"\\n%s: %.2f%%\" % (nn_model.metrics_names[1], scores_train[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has ~ 97% accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 6, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = nn_model.predict(test_set_x)\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 57us/step\n",
      "\n",
      "acc: 96.27%\n"
     ]
    }
   ],
   "source": [
    "scores_test = nn_model.evaluate(test_set_x, test_set_y)\n",
    "print(\"\\n%s: %.2f%%\" % (nn_model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has ~96% accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try and look at the different test cases and check which all have gone wrong. Feel free to change the index numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc0df839128>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc0df7f86a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index  = 9997\n",
    "k = test_set_x[index, :]\n",
    "k = k.reshape((28, 28))\n",
    "plt.title('Label is {label}'.format(label=(predictions[index], np.argmax(test_set_y, axis = 1)[index])))\n",
    "plt.imshow(k, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
